# Computer Cursor Control Using Facial Gestures
 The conformity would function in live moment when input are communicated from user so disable as well as normal people could easily achieve remarkable function using computer.
Every model offers two significant functions. A pointer to detect the face and a predictor to predict the landmarks. 
You can get the trained model file from http://dlib.net/files, click on shape_predictor_68_face_landmarks.dat.bz2. Please note the model, .dat file has to be in the project folder.
**Setup :**
Install and setup Anaconda.
Open Anaconda Prompt.
Enter conda create -n dlib_env
Enter pip install cmake
Enter conda install -c conda-forge dlib
Enter pip install opencv-contrib-python
Enter pip install imutils
Enter pip install pyautogui

**Check Installation :** 
Enter python
Enter import dlib
Enter dlib.__version__
Enter import cv2
Enter cv2.__version__
quit()
Done

**How to run :**
Open project folder in cmd using cd path command
Activate dlib environment using conda activate dlib_env
Run python main.py

  [face-recognition-using-opencv](https://user-images.githubusercontent.com/67729118/128348073-d24079bf-c037-47f5-a5d0-77ee6f28d08d.jpg)


The conformity would function in live moment when input are communicated from user so disable as well as normal people could easily achieve remarkable function using computer. Future work will include efficient user input in low light conditions. Customization options for gestures and computer activity can be added along with voice recognition-based typing methods. The system can be turnedinto an executable structure.
