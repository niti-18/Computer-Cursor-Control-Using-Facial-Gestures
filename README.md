# Computer Cursor Control Using Facial Gestures
 The conformity would function in live moment when input are communicated from user so disable as well as normal people could easily achieve remarkable function using computer.





Every model offers two significant functions. A pointer to detect the face and a predictor to predict the landmarks. You can get the trained model file from http://dlib.net/files, click on shape_predictor_68_face_landmarks.dat.bz2. Please note the model, .dat file has to be in the project folder.



Setup :
1 Install and setup Anaconda.
2 Open Anaconda Prompt.
3 Enter conda create -n dlib_env
4 Enter pip install cmake
5 Enter conda install -c conda-forge dlib
6 Enter pip install opencv-contrib-python
7 Enter pip install imutils
8 Enter pip install pyautogui


Check Installation : 
1 Enter python
2 Enter import dlib
3 Enter dlib.__version__
4 Enter import cv2
5 Enter cv2.__version__
6 quit()
Done


How to run :
1 Open project folder in cmd using cd path command
2 Activate dlib environment using conda activate dlib_env
3 Run python main.py


The conformity would function in live moment when input are communicated from user so disable as well as normal people could easily achieve remarkable function using computer. Future work will include efficient user input in low light conditions. Customization options for gestures and computer activity can be added along with voice recognition-based typing methods. The system can be turnedinto an executable structure.
